{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74557173",
   "metadata": {
    "papermill": {
     "duration": 0.002915,
     "end_time": "2023-06-01T05:11:09.941518",
     "exception": false,
     "start_time": "2023-06-01T05:11:09.938603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "_Adapted from notebook used by [nbclab.github.io](https://nbclab.github.io)._\n",
    "\n",
    "# Retrieve new publications from PubMed \n",
    "\n",
    "This notebook is used to search for and retrieve latest publications by Dr. Khan using BioPython's PubMed search tool. A publication-specific MarkDown file is generated for each unique paper, with many elements automatically set up. As noted in the original notebook, you generally should check that the link to the markdown file exists. Unfortunately, preprints cannot be found via this method (though they can be added manually). This notebook cannot find new preprints. The process is automated and runs monthly using Github actions.\n",
    "\n",
    "## Steps (via Github or manual)\n",
    "\n",
    "1. Run this notebook.\n",
    "2. If any new papers were grabbed, check the following:\n",
    "    1. The paper has either of the lab PIs as an author. Ensure that it isn't by *another* AR Khan.\n",
    "    2. The paper is not a duplicate of a preprint or another version of the paper. If so, merge the two versions.\n",
    "3. Save the changes to the notebook.\n",
    "4. Push changes to the notebook and affected files to GitHub.\n",
    "5. Open a pull request to khanlab/khanlab.github.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22f3858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T05:11:09.947936Z",
     "iopub.status.busy": "2023-06-01T05:11:09.947357Z",
     "iopub.status.idle": "2023-06-01T05:11:10.235608Z",
     "shell.execute_reply": "2023-06-01T05:11:10.234774Z"
    },
    "papermill": {
     "duration": 0.293966,
     "end_time": "2023-06-01T05:11:10.237893",
     "exception": false,
     "start_time": "2023-06-01T05:11:09.943927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os \n",
    "\n",
    "from Bio import Entrez, Medline\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526e19d",
   "metadata": {
    "papermill": {
     "duration": 0.002182,
     "end_time": "2023-06-01T05:11:10.242502",
     "exception": false,
     "start_time": "2023-06-01T05:11:10.240320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Check existing publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9095c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T05:11:10.248080Z",
     "iopub.status.busy": "2023-06-01T05:11:10.247708Z",
     "iopub.status.idle": "2023-06-01T05:11:10.256374Z",
     "shell.execute_reply": "2023-06-01T05:11:10.255647Z"
    },
    "papermill": {
     "duration": 0.013702,
     "end_time": "2023-06-01T05:11:10.258281",
     "exception": false,
     "start_time": "2023-06-01T05:11:10.244579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First count number of articles from previous grab\n",
    "pub_data = \"_data/publications/publications.csv\"\n",
    "\n",
    "# Update count of publications from existing file\n",
    "old_count = 0 \n",
    "if os.path.isfile(pub_data):\n",
    "    df_old = pd.read_csv(pub_data)\n",
    "    old_count = len(df_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da017a87",
   "metadata": {
    "papermill": {
     "duration": 0.002058,
     "end_time": "2023-06-01T05:11:10.262595",
     "exception": false,
     "start_time": "2023-06-01T05:11:10.260537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Perform new query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "700613de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T05:11:10.268302Z",
     "iopub.status.busy": "2023-06-01T05:11:10.267916Z",
     "iopub.status.idle": "2023-06-01T05:11:10.272188Z",
     "shell.execute_reply": "2023-06-01T05:11:10.271443Z"
    },
    "papermill": {
     "duration": 0.008857,
     "end_time": "2023-06-01T05:11:10.273627",
     "exception": false,
     "start_time": "2023-06-01T05:11:10.264770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only grab papers from after the lab PI came to UWO\n",
    "search_criteria = ['''\"Khan AR\"[AUTH] AND (\"2015/01/01\"[PDAT] : \"3000/12/31\"[PDAT]) AND\n",
    "                    (\"Western University\"[AFFL] OR \"University of Western Ontario\"[AFFL] OR\n",
    "                     \"Brain and Mind Institute\"[AFFL] OR \"Robarts Research Institute\"[AFFL])''']\n",
    "\n",
    "# Email required to search\n",
    "Entrez.email = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad1de07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T05:11:10.279595Z",
     "iopub.status.busy": "2023-06-01T05:11:10.279052Z",
     "iopub.status.idle": "2023-06-01T05:11:12.540756Z",
     "shell.execute_reply": "2023-06-01T05:11:12.539987Z"
    },
    "papermill": {
     "duration": 2.267402,
     "end_time": "2023-06-01T05:11:12.543224",
     "exception": false,
     "start_time": "2023-06-01T05:11:10.275822",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of publications containing \"Khan AR\"[AUTH] AND (\"2015/01/01\"[PDAT] : \"3000/12/31\"[PDAT]) AND\n",
      "                    (\"Western University\"[AFFL] OR \"University of Western Ontario\"[AFFL] OR\n",
      "                     \"Brain and Mind Institute\"[AFFL] OR \"Robarts Research Institute\"[AFFL]): 66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving identified publications to csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2317/990535001.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df_old.append(new_pubs)\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "# Publications to skip (possibly due to another user with same initial)\n",
    "skip_pmids = [32971934, 29641820, 29634829]\n",
    "skip_pmids = [str(pmid) for pmid in skip_pmids]\n",
    "\n",
    "for TERM in search_criteria:\n",
    "    search = Entrez.esearch(db=\"pubmed\", retmax=\"2\", term=TERM)\n",
    "    result = Entrez.read(search)\n",
    "    print(f\"Total number of publications containing {TERM}: {result['Count']}\")\n",
    "    \n",
    "    search_all = Entrez.esearch(db=\"pubmed\", term=TERM, retmax=result[\"Count\"])\n",
    "    result_all = Entrez.read(search_all)\n",
    "    ids_all = result_all['IdList']\n",
    "    pubs_all = Entrez.efetch(db=\"pubmed\", id=ids_all, rettype='medline', retmode='text')\n",
    "    records = Medline.parse(pubs_all)\n",
    "    \n",
    "    acceptable_formats = [\"journal article\", \"comparative study\", \"editorial\"]\n",
    "    \n",
    "    for record in records:\n",
    "        if any([type_.lower() in acceptable_formats for type_ in record.get('PT')]):\n",
    "            pmid = record.get(\"PMID\")\n",
    "            pmcid = record.get(\"PMC\", \"\")\n",
    "            \n",
    "            doi = [aid for aid in record.get(\"AID\", []) if aid.endswith(\" [doi]\")]\n",
    "            if doi:\n",
    "                doi = doi[0].replace(\" [doi]\", \"\")\n",
    "            else:\n",
    "                doi = \"\"\n",
    "            \n",
    "            title = record.get(\"TI\").rstrip(\".\")\n",
    "            authors = record.get(\"AU\")\n",
    "            \n",
    "            pub_date = parser.parse(record.get(\"DP\"))\n",
    "            journal = record.get('TA')\n",
    "            volume = record.get('VI', '')\n",
    "            issue = record.get('IP', '')\n",
    "            pages = record.get('PG', '')\n",
    "            \n",
    "            row = [pmid, pmcid, doi, title, authors, pub_date.year, pub_date.month,\n",
    "                   pub_date.day, journal, volume, issue, pages]\n",
    "            rows += [row]\n",
    "            \n",
    "df = pd.DataFrame(columns=['pmid', 'pmcid', 'doi', 'title', 'authors',\n",
    "                           'year', 'month', 'day',\n",
    "                           'journal', 'volume', 'issue', 'pages'],\n",
    "                  data=rows)\n",
    "df = df[~df[\"pmid\"].isin(skip_pmids)]\n",
    "df['pmid'] = df['pmid'].astype(int)\n",
    "\n",
    "new_pubs = df[~df['pmid'].isin(df_old['pmid'])]\n",
    "\n",
    "# Append to old pubs to solve date issue\n",
    "df = df_old.append(new_pubs)\n",
    "df = df.sort_values(by=['year', 'month', 'day'], ascending=False)\n",
    "df = df.fillna('')\n",
    "\n",
    "# Save all relevant info from articles to a csv.\n",
    "print(\"Saving identified publications to csv...\")\n",
    "df.to_csv('_data/publications/publications.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70df731e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T05:11:12.550160Z",
     "iopub.status.busy": "2023-06-01T05:11:12.549484Z",
     "iopub.status.idle": "2023-06-01T05:11:12.557761Z",
     "shell.execute_reply": "2023-06-01T05:11:12.557012Z"
    },
    "papermill": {
     "duration": 0.014056,
     "end_time": "2023-06-01T05:11:12.559883",
     "exception": false,
     "start_time": "2023-06-01T05:11:12.545827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 total articles found.\n",
      "0 new articles found.\n",
      "\n",
      "New publications found:\n"
     ]
    }
   ],
   "source": [
    "# Add papers we already have pages for.\n",
    "if len(skip_pmids) > 0:\n",
    "    for pmid in skip_pmids:\n",
    "        df = df[df['pmid'] != pmid]\n",
    "        \n",
    "print(f\"{len(df)} total articles found.\")\n",
    "print(f\"{len(df) - old_count} new articles found.\")\n",
    "\n",
    "print(\"\\nNew publications found:\")\n",
    "for _, pub in new_pubs.iterrows():\n",
    "    print(f\"Title: {pub['title']} ({pub['journal']})\")\n",
    "    print(f\"Authors: {pub['authors']}\")\n",
    "    print(f\"Journal (Date): {pub['journal']} ({pub['month']}/{pub['day']}/{pub['year']})\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76e9b21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T05:11:12.566191Z",
     "iopub.status.busy": "2023-06-01T05:11:12.565920Z",
     "iopub.status.idle": "2023-06-01T05:11:12.577664Z",
     "shell.execute_reply": "2023-06-01T05:11:12.576868Z"
    },
    "papermill": {
     "duration": 0.016975,
     "end_time": "2023-06-01T05:11:12.579433",
     "exception": false,
     "start_time": "2023-06-01T05:11:12.562458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>journal</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pmid, pmcid, doi, title, authors, year, month, day, journal, volume, issue, pages]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also output the df in case output limit exceeded\n",
    "new_pubs"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "khanlab.github.io",
   "language": "python",
   "name": "khanlab.github.io"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.179503,
   "end_time": "2023-06-01T05:11:12.901618",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/runner/work/khanlab.github.io/khanlab.github.io/get_publications.ipynb",
   "output_path": "/home/runner/work/khanlab.github.io/khanlab.github.io/get_publications.ipynb",
   "parameters": {},
   "start_time": "2023-06-01T05:11:08.722115",
   "version": "2.3.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "f5bc17ec438c58579c8fad5c2a3a4c0e08154707e8777e80eae011e8f60ceb8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}